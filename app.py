import streamlit as st
import requests
from bs4 import BeautifulSoup
import jieba
from collections import Counter
import pandas as pd
import plotly.express as px
from pyecharts import options as opts
from pyecharts.charts import WordCloud, Bar, Pie
from streamlit_echarts import st_pyecharts

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ–‡æœ¬åˆ†æå¯è§†åŒ–å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ç®€åŒ–CSSæ ·å¼ï¼Œé¿å…DOMæ“ä½œå†²çª
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stApp {
        background-color: #f5f7f9;
    }
    h1 {
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .plot-container {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    </style>
""", unsafe_allow_html=True)

def get_text_content(url):
    """è·å–ç½‘é¡µæ–‡æœ¬å†…å®¹"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        if response.status_code != 200:
            st.error(f"è·å–å†…å®¹å¤±è´¥: HTTPçŠ¶æ€ç  {response.status_code}")
            return ""
            
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ç§»é™¤æ— å…³æ ‡ç­¾
        for tag in soup(['script', 'style', 'iframe']):
            tag.decompose()
            
        text = soup.get_text()
        
        if not text.strip():
            st.error("æå–çš„æ–‡æœ¬å†…å®¹ä¸ºç©º")
            return ""
            
        return text
        
    except Exception as e:
        st.error(f"è·å–å†…å®¹å¤±è´¥: {str(e)}")
        return ""

def process_text(text):
    """æ–‡æœ¬åˆ†è¯å’Œç»Ÿè®¡"""
    try:
        # åˆ†è¯
        words = jieba.cut(text)
        # è¿‡æ»¤å•å­—è¯
        words = [w for w in words if len(w) > 1]
        
        # ç»Ÿè®¡è¯é¢‘
        word_freq = Counter(words)
        
        if not word_freq:
            st.error("æœªèƒ½æå–åˆ°æœ‰æ•ˆè¯é¢‘")
            return {}
            
        return word_freq
        
    except Exception as e:
        st.error(f"åˆ†è¯å¤„ç†å¤±è´¥: {str(e)}")
        return {}

def create_visualizations(word_freq):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    if not word_freq:
        return
        
    # å‡†å¤‡æ•°æ®
    items = list(word_freq.items())
    words, freqs = zip(*sorted(items, key=lambda x: x[1], reverse=True)[:20])
    df = pd.DataFrame({'è¯è¯­': words, 'é¢‘æ¬¡': freqs})
    
    # ä½¿ç”¨tabsæ›¿ä»£columnsï¼Œå‡å°‘DOMæ“ä½œ
    tab1, tab2 = st.tabs(["è¯é¢‘ç»Ÿè®¡", "è¯äº‘å›¾"])
    
    with tab1:
        # æŸ±çŠ¶å›¾
        fig = px.bar(df, x='è¯è¯­', y='é¢‘æ¬¡', title='è¯é¢‘åˆ†å¸ƒ')
        st.plotly_chart(fig, use_container_width=True)
        
    with tab2:
        # è¯äº‘å›¾
        wordcloud = (
            WordCloud()
            .add("", items[:50], word_size_range=[20, 100])
            .set_global_opts(title_opts=opts.TitleOpts(title="è¯äº‘å›¾"))
        )
        st_pyecharts(wordcloud)

def main():
    st.title("æ–‡æœ¬åˆ†æå¯è§†åŒ–å·¥å…·")
    
    # ä½¿ç”¨å•åˆ—å¸ƒå±€ï¼Œå‡å°‘å¤æ‚çš„å¸ƒå±€æ“ä½œ
    url = st.text_input("è¾“å…¥æ–‡ç« URL", placeholder="è¯·è¾“å…¥ç½‘å€...")
    
    if url:
        with st.spinner('æ­£åœ¨è·å–æ–‡ç« å†…å®¹...'):
            text = get_text_content(url)
            
        if text:
            with st.spinner('æ­£åœ¨åˆ†ææ–‡æœ¬...'):
                word_freq = process_text(text)
                
            if word_freq:
                create_visualizations(word_freq)
    else:
        st.info('è¯·è¾“å…¥è¦åˆ†æçš„æ–‡ç« URL')

if __name__ == "__main__":
    main()
